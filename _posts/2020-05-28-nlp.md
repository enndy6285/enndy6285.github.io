---
layout: post
title: Text Preprocessing for NLP
---

### Introduction
Yelp is one of the largest platforms for customer generated business reviews with over 211 milion cumulative reviews to date. This wealth of information is valuable not only to consumers but the businesses themselves. A five star rating is the goal of every restaurant but what distinguishes a 5-star restaurant?

### Objective
The goal of this project is to use NLP techniques to analyze Yelp text reviews in order to gain insight on features that are predictive of a 5-star rating.

### The Data
Data was obtained from the Yelp Open Dataset available at [Yelp Open Dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset). It was uploaded into MongoDB. A subset consisting of Toronto restaurant reviews was then downloaded for analysis

### Methodology
Today we will focus on text preprocessing and how this affects our final analysis. NLTK packages were used for processing. Output we will be looking at will be topics generated after text vectorization (TF-IDF) and topic modeling (NMF, number of topics set at 50).

### Text Preprocessing
Text preprocessing serves as the backbone of NLP. The phrase "garbage in, garbage out" certainly applies here. 

#### Basic Text Cleaning
First we will do some basic cleaning including removing special characters, punctuation, and capitalizations. This can be performed with regular expressions:

```
text = re.sub('\w*\d\w*', ' ', text)
text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text.lower())
```

Sample topics produced from topic modeling:
>Topic  0 - salad, steak, dressing, greek, pasta, ordered, kale, caesar, bread, side
 Topic  1 - food, service, excellent, fast, slow, bad, authentic, ok, indian, customer
 Topic  2 - us, table, came, server, asked, minutes, told, said, waitress, got
 Topic  3 - sushi, sashimi, roll, rolls, salmon, ayce, tempura, fish, japanese, maki
 Topic  4 - pizza, crust, toppings, pizzas, pasta, thin, slice, italian, sauce, pepperoni
 Topic  5 - ramen, broth, tonkotsu, noodles, miso, egg, kinton, bowl, spicy, shoyu

#### Stemming
Next will use stemming to reduce word tokens to their base form. This will consolidate words including plural forms such as "pizza" and "pizzas" seen above. The stemmer used was NLTK's SnowballStemmer.

Sample topics:
>Topic  0 - us, ask, tabl, server, even, one, came, said, becaus, bill
 Topic  1 - great, atmospher, spot, awesom, experi, select, vibe, fantast, valu, music
 Topic  2 - wait, minut, long, line, hour, seat, tabl, worth, get, min
 Topic  3 - sandwich, bread, chees, veal, bun, grill, brisket, tri, bacon, meat
 Topic  4 - pizza, crust, top, pasta, slice, thin, chees, sauc, italian, pepperoni
 Topic  5 - sushi, sashimi, ayc, qualiti, japanes, piec, salmon, tempura, chef, eat

#### Stop Words
It looks like we have some reasonably logical topics with a notable grouping by type of cuisine. While this may be interesting, this information is already captured by other Yelp metadata (business categories) and not particularly useful to an individual restaurant. Therefore I tried removing food object related words through the use of stopwords. So far we have been using a basic set of english stopwords included in the NLTK package. While there is not a separate food word list, we can create one using NLTK's wordnet. We can also manually add additional food item words.

```
from nltk.corpus import wordnet as wn

stop_words = nltk.corpus.stopwords.words('english')

food = wn.synset('food.n.02')
food_words = set([w for s in food.closure(lambda s:s.hyponyms()) for w in s.lemma_names()])
food_words = list(f.strip('_').replace('_',' ').lower() for f in food_words)

more_stop_words = ['cream', 'chicken', 'burger', 'pizza', 'milk', 'pickl',
                    'kimchi', 'sushi', 'ramen', 'thai', 'dim', 'tea', 'banh', 'khao',
                   'indian', 'korean', 'chines', 'noodl', 'tom yum',
                   'fast food', 'food court', 'toronto', 'place',
                  'back', 'recommend', 'better', 'best', 'noth', 'favourit', 'favorit', 'star',
                   'disappoint', 'love', 'definit']

stop_words.extend(food_words)
stop_words.extend(more_stop_words)
```

Sample topics:
>Topic  0 - restaur, japanes, area, sum, italian, mani, famili, decor, authent, high
 Topic  1 - great, atmospher, spot, awesom, vibe, select, fantast, valu, music, patio
 Topic  2 - us, ask, tabl, server, came, said, told, bill, waitress, even
 Topic  3 - food, authent, qualiti, atmospher, court, mediocr, mexican, fast, experi, bad
 Topic  4 - good, pretti, overal, valu, thing, bake, usual, choic, ambienc, look
 Topic  5 - veri, tasti, also, well, attent, clean, busi, pleasant, lot, happi

#### N-grams




The data was split into training and test sets. After running the 3 classification models on the training data with 10-fold cross validation, logistic regression and random forest appeared to perform best. The error metrics for both models are as follows:

Logistic Regression metrics:
![Logistic Regression scores]({{ site.url }}/images/2020-05-12/lr_val_table.png)

Random Forest metrics:
![Random Forest scores]({{ site.url }}/images/2020-05-12/rf_val_table.png)

Although the random forest model has slightly higher overall accuracy, it performs lower in the first two metrics of interest - class 0 recall and class 1 F1. Therefore, I decided to use logistic regression as my final model. After retraining on the entire training set, here is how it performs on the set-aside test data:

![Logistic Regression Confusion Matrix]({{ site.url }}/images/2020-05-12/lr_test_matrix.png)

The final result is a classification model that prioritizes class 1 and class 3. In fact, it weights these 2 classes to the point that the model resembles binary classification with almost no predictions made for class 2. With more time, it would be interesting to see how the models would look with additional fine-tuning of class weights.

### Conclusion
In order to properly evaluate a model, it is necessary to determine what metrics will be used for evaluation. This is especially true for multi-class problems which can be more difficult to summarize with a single measure. 